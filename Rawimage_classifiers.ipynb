{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar\"\n",
    "\n",
    "if dataset_name == \"cifar\":\n",
    "    dataset_path = r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\data\\cifar\"\n",
    "    \n",
    "if dataset_name == \"mnist\":\n",
    "    dataset_path = r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\data\\mnist\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_path,\"datasets\",\"cifar-10-batches-py\\\\batches.meta\"), 'rb') as fp:\n",
    "    label_names = pickle.load(fp)['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_path,\"datasets\",dataset_name+\"_labels\"), 'rb') as fp:\n",
    "    targets = pickle.load(fp)\n",
    "\n",
    "targets = np.array(targets) ##new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in label_names:\n",
    "\n",
    "#     os.makedirs(os.path.join(dataset_path,\"reconst_class_images\",i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000):\n",
    "\n",
    "#     tg = targets[i]\n",
    "#     shutil.copy(os.path.join(dataset_path,\"reconstructed_images\",str(i)+\".png\"),os.path.join(dataset_path,\"reconst_class_images\",label_names[tg],str(i)+\".png\"))\n",
    "#     # print(os.path.join(dataset_path,\"reconstructed_images\",str(i)+\".png\"),os.path.join(dataset_path,\"reconst_class_images\",label_names[tg],str(i)+\".png\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_raw_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "\n",
    "    img = cv2.imread(os.path.join(dataset_path,\"reconstructed_images\",str(i)+\".png\"),cv2.IMREAD_GRAYSCALE)\n",
    "    input_raw_list.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_reconst = np.array(input_raw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\data\\cifar\\datasets\\cifar_10K_dataset.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = torch.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_reconst_list = []\n",
    "\n",
    "for i in input_dataset:\n",
    "\n",
    "    input_reconst_list.append(i[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_org = np.array(input_reconst_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(input_array,tg,c_name,d_name,scale,pca_val = None):\n",
    "\n",
    "    input_data = input_array\n",
    "    \n",
    "    if scale == True:\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        input_data = scaler.fit_transform(input_data)\n",
    "\n",
    "    if pca_val != None:\n",
    "\n",
    "        pca = PCA(n_components=pca_val)\n",
    "        input_data = pca.fit_transform(input_data)\n",
    "        \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(input_data, tg, test_size=0.25, random_state=42)\n",
    "\n",
    "    if c_name == \"logit\":\n",
    "\n",
    "        logisticRegr = LogisticRegression(solver = 'sag',penalty = 'l2')\n",
    "        logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = logisticRegr.predict(x_test)\n",
    "\n",
    "        # Use score method to get accuracy of model\n",
    "        test_accuracy = logisticRegr.score(x_test, y_test)\n",
    "        train_accuracy = logisticRegr.score(x_train,y_train)\n",
    "        \n",
    "    if c_name == \"forest\":\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=300,max_depth=14)\n",
    "        rf.fit(x_train, y_train)    \n",
    "\n",
    "        y_pred = rf.predict(x_test)\n",
    "        y_pred_train = rf.predict(x_train)\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Metrics\n",
    "\n",
    "    # print(\"Test accuracy\",test_accuracy,\"Train accuracy\",train_accuracy)\n",
    "            \n",
    "    cm = metrics.confusion_matrix(y_test, y_pred) # Confusion matrix\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5,cbar=False, square = True, cmap = 'Blues_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    all_sample_title = 'Test Accuracy: {0} / Train Accuracy: {1}'.format(test_accuracy,train_accuracy)\n",
    "    note = 'Confusion matric for {0} with PCA (={1}) on {2} dataset'.format(c_name,pca_val,d_name)\n",
    "    plt.figtext(0.5, 0.01,note, ha=\"center\", fontsize=15,color =\"black\") #bbox={\"facecolor\":\"orange\", \"alpha\":0.5, \"pad\":5})\n",
    "    plt.title(all_sample_title, size = 15);\n",
    "    \n",
    "    plt.savefig(os.path.join(dataset_path,\"plots\\\\metrics\",note+\".pdf\"))\n",
    "    plt.show()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_reconst = input_reconst.reshape([10000,28*28])\n",
    "input_org = input_org.reshape([10000,28*28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier(input_array,targets,'forest',True,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = 500\n",
    "\n",
    "print( \"------- Original Image ----------------\")\n",
    "classifier(input_org,targets,'logit',\"original \"+dataset_name,True,pca_features)\n",
    "print(\"\\n\", \"------- Reconstructed Image ----------------\")\n",
    "classifier(input_reconst,targets,'logit',\"reconstructed \"+dataset_name,True,pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
