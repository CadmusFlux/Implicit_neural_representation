{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "# Data Processing \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "# Plotting \n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Utility Tools\n",
    "\n",
    "import itertools as it\n",
    "import pickle\n",
    "import random\n",
    "import umap\n",
    "import gc\n",
    "import os\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar\"\n",
    "\n",
    "if dataset_name == \"cifar\":\n",
    "    dataset_path = r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\data\\cifar\"\n",
    "    \n",
    "if dataset_name == \"mnist\":\n",
    "    dataset_path = r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\data\\mnist\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_path,\"datasets\",dataset_name+\"_labels\"), 'rb') as fp:\n",
    "    targets = pickle.load(fp)\n",
    "\n",
    "with open(os.path.join(dataset_path,\"datasets\",\"weights_dictionary.pkl\"), 'rb') as fp:\n",
    "    weights_dict = pickle.load(fp)\n",
    "\n",
    "targets = np.array(targets) ##new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_array = np.array(tuple(weights_dict.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig(embed,tg,digits,d_name): \n",
    "\n",
    "    \"\"\" Plot's UMAP clustering scatter plot\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    embed : The embedding created by UMAP\n",
    "    tg : The targets for each weight array or img\n",
    "    digits: How amny digits are present (0-9)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    # print(embed.shape,tg.shape)\n",
    "    sc = plt.scatter(embed[:, 0], embed[:, 1], c=tg, cmap='Spectral', s=10)\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    plt.legend(handles=sc.legend_elements()[0], labels=list(digits), prop={'size': 10})\n",
    "\n",
    "    plt.title(\"UMAP projection of classes {0} - {1} of {2}\".format(digits[0],digits[1],d_name), fontsize=15);\n",
    "    \n",
    "    \n",
    "    # plt.show()\n",
    "    # plt.savefig(os.path.join(dataset_path,\"plots\\\\umaps\",\"{digit1}_{digit2}.pdf\".format(digit1 = digits[0],digit2 = digits[1]))) --> uncomment\n",
    "\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_arrays(arrays, set_seed=-1):\n",
    "    \n",
    "    \"\"\"Shuffles arrays in-place, in the same order, along axis=0\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    arrays : List of NumPy arrays.\n",
    "    set_seed : Seed value if int >= 0, else seed is random.\n",
    "    \"\"\"\n",
    "    assert all(len(arr) == len(arrays[0]) for arr in arrays)\n",
    "    seed = np.random.randint(0, 2**(32 - 1) - 1) if set_seed < 0 else set_seed\n",
    "\n",
    "    for arr in arrays:\n",
    "        rstate = np.random.RandomState(seed)\n",
    "        rstate.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umaps(weights,target,digits):\n",
    "\n",
    "    '''\n",
    "        Function to return an array with only classes present in the digits variable. If the digits array has ([0,1]), then pnly instances\n",
    "        where target == 0/1 are chosen and stacked together.\n",
    "\n",
    "        return:\n",
    "\n",
    "            wa --> new weights array\n",
    "            ta --> new target array\n",
    "    '''\n",
    "\n",
    "    wa = []\n",
    "    ta = []\n",
    "\n",
    "    for i in digits:\n",
    "\n",
    "        index = np.where(target == i)\n",
    "\n",
    "        weights_array_temp = weights[tuple(index)]\n",
    "        targets_array_temp = np.ones(weights_array_temp.shape[0])*target[index[0][0]]\n",
    "\n",
    "        wa.append(weights_array_temp)\n",
    "        ta.append(targets_array_temp)\n",
    "\n",
    "\n",
    "    wa = np.vstack(wa)\n",
    "    ta = np.hstack(ta)\n",
    "\n",
    "    shuffle_arrays([wa,ta])\n",
    "\n",
    "    return wa,ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in it.combinations(np.arange(2), 2):\n",
    "\n",
    "    ws,ts = plot_umaps(weights_array[:,8400:8450],targets,np.array([a,b]))\n",
    "    embedding = reducer.fit_transform(ws)\n",
    "\n",
    "    plot_fig(embedding,ts,np.array([a,b]),dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo = 3050\n",
    "\n",
    "# while lo <9051:\n",
    "\n",
    "layers = [0,6400,6450,8950,9000,9050,9051]\n",
    "images_layers = []\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20,20))\n",
    "\n",
    "for lo in range(len(layers)-3):\n",
    "    \n",
    "    for a,b in it.combinations(np.arange(2), 2):\n",
    "        \n",
    "        print(\"Plot for {0}-{1}\".format(layers[lo],layers[lo+1]))\n",
    "        ws,ts = plot_umaps(weights_array[:,layers[lo]:layers[lo+1]],targets,np.array([a,b]))\n",
    "        embedding = reducer.fit_transform(ws)\n",
    "\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], c=ts, cmap='Spectral', s=10)\n",
    "\n",
    "    # lo += 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(20,20))\n",
    "for idx, image in enumerate(images_layers):\n",
    "    row = idx // 2\n",
    "    col = idx % 3\n",
    "    axes[row, col].axis(\"off\")\n",
    "    axes[row, col].imshow(image, cmap=\"gray\", aspect=\"auto\")\n",
    "plt.subplots_adjust(wspace=.05, hspace=.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2,3),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "# fig.add_collection(images_layers)\n",
    "# # for ax, im in zip(grid,random.sample( range(0, 10000), 4)):\n",
    "for ax, im in zip(grid,np.arange(len(images_layers))):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    \n",
    "    ax.imshow(images_layers[im])\n",
    "    # fig.savefig(r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\plots\\Observations\\cifar_weights_plotted.pdf\")\n",
    "    plt.title(\"Weights array plotted for image no {image_no}\".format(image_no=im))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(input_array,labels,c_name,scale,pca_val = None):\n",
    "\n",
    "    input_data = input_array\n",
    "    \n",
    "    if scale == True:\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        input_data = scaler.fit_transform(input_data)\n",
    "\n",
    "    if pca_val != None:\n",
    "\n",
    "        pca = PCA(n_components=pca_val)\n",
    "        input_data = pca.fit_transform(input_data)\n",
    "        \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    if c_name == \"logit\":\n",
    "\n",
    "        logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "        logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = logisticRegr.predict(x_test)\n",
    "\n",
    "        # Use score method to get accuracy of model\n",
    "        test_accuracy = logisticRegr.score(x_test, y_test)\n",
    "        train_accuracy = logisticRegr.score(x_train,y_train)\n",
    "        \n",
    "    if c_name == \"forest\":\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=300,max_depth=14)\n",
    "        rf.fit(x_train, y_train)    \n",
    "\n",
    "        y_pred = rf.predict(x_test)\n",
    "        y_pred_train = rf.predict(x_train)\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Metrics\n",
    "\n",
    "    print(\"Test accuracy\",test_accuracy,\"Train accuracy\",train_accuracy)\n",
    "    \n",
    "    cm = metrics.confusion_matrix(y_test, y_pred) # Confusion matrix\n",
    "\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    all_sample_title = 'Accuracy Score: {0}'.format(test_accuracy)\n",
    "    plt.title(all_sample_title, size = 15);\n",
    "    # plt.savefig(\"C:/Users/ayush/OneDrive/Desktop/UoE/Dissertation/Implicit Networks/plots/metrics/{classifier}_{pca}.pdf\".format(classifier = c_name,pca = pca_val))\n",
    "    plt.savefig(os.path.join(dataset_path,\"plots\\\\metrics\",\"CIFAR_Weights_{classifier}_{pca}.pdf\".format(classifier = c_name,pca = pca_val)))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(weights_array[:,6400:6450],targets,'logit',True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(weights_array,targets,'forest',True,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(targets == 0)[0][:4].tolist()\n",
    "index.extend(np.where(targets == 3)[0][:4].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2,4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "# for ax, im in zip(grid,random.sample( range(0, 10000), 4)):\n",
    "for ax, im in zip(grid,index):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    \n",
    "    ax.imshow(weights_dict[str(im)][:9025].reshape(95,95),cmap = 'gray')\n",
    "    # fig.savefig(r\"C:\\Users\\ayush\\OneDrive\\Desktop\\UoE\\Dissertation\\Implicit Networks\\plots\\Observations\\cifar_weights_plotted.pdf\")\n",
    "    plt.title(\"Weights array plotted for image no {image_no}\".format(image_no=im))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.where(targets==4)[0][1:]:\n",
    "\n",
    "    print(np.linalg.norm(weights_dict['4'] - weights_dict[str((x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [0,6400,6450,8950,9000,9050,9051]\n",
    "l_names = [\"Null\",\"Layer 1\",\"Bias 1\",\"Layer 2\",\"Bias 2\",\"Layer 3\",\"Output\"]\n",
    "\n",
    "\n",
    "for i in range(1,len(layers)):\n",
    "    print(l_names[i],\"-->\",layers[i]-layers[i-1],\"-->\",np.abs(weights_array[layers[i-1]:layers[i]]).sum())\n",
    "    print(np.abs(weights_array[i-1:i]))\n",
    "    print(\"\\n---- END ------\")\n",
    "    # weights_array[layers[i-1]:layers[i]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(weights_array[0]).abs().nlargest(100,0)\n",
    "temp = pd.DataFrame(np.int64(np.floor(dataset.index.values / 50) * 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_counts(weights):\n",
    "\n",
    "    dataset = pd.DataFrame(weights).abs().nlargest(100,0)\n",
    "    temp = pd.DataFrame(np.int64(np.floor(dataset.index.values / 50) * 50)) ## change (number to x) to round to closest x muliplte\n",
    "\n",
    "    return temp.apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pd = []\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    list_pd.append(pixel_counts(weights_array[i]))\n",
    "\n",
    "df = pd.concat(list_pd, axis=1)\n",
    "\n",
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_array[600][8900:8950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_array[600][8900:8950]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC, LinearSVC\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient = []\n",
    "# n_supp = []\n",
    "# sup_vec = []\n",
    "# i = 0\n",
    "# df = pd.DataFrame(columns = ['c','gamma','train_acc','test_acc'])\n",
    "# for c in [10]:\n",
    "#     for g in [0.01]:\n",
    "#         svm = SVC(kernel='rbf', C=c, gamma=g)\n",
    "#         model = svm.fit(x_train, y_train)\n",
    "#         globals()['model%s' % i] = model\n",
    "#         d_coef = svm.dual_coef_\n",
    "#         support = svm.n_support_\n",
    "#         sv = svm.support_\n",
    "    \n",
    "#         p_tr = svm.predict(x_train)\n",
    "#         a_tr = accuracy_score(y_train, p_tr)\n",
    "    \n",
    "#         pred = svm.predict(x_test)\n",
    "#         a = accuracy_score(y_test, pred)\n",
    "    \n",
    "#         coefficient.append(d_coef)\n",
    "#         n_supp.append(support)\n",
    "#         sup_vec.append(sv)\n",
    "#         df.loc[i] = [c,g,a_tr,a]\n",
    "#         i=i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = np.array([0,5])\n",
    "\n",
    "# wa = []\n",
    "# ta = []\n",
    "\n",
    "# for i in list1:\n",
    "\n",
    "#     index = np.where(targets == i)\n",
    "\n",
    "#     weights_array_temp = weights_array[tuple(index)]\n",
    "#     targets_array_temp = np.ones(weights_array_temp.shape[0])*targets[index[0][0]]\n",
    "\n",
    "#     wa.append(weights_array_temp)\n",
    "#     ta.append(targets_array_temp)\n",
    "\n",
    "\n",
    "# wa = np.vstack(wa)\n",
    "# ta = np.hstack(ta)\n",
    "\n",
    "# shuffle_arrays([wa,ta])\n",
    "\n",
    "# embedding = reducer.fit_transform(np.delete(wa,np.s_[9050:-1],1))\n",
    "\n",
    "# plot_fig(embedding,ta,list1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_pd = pd.DataFrame.from_dict(weights)\n",
    "# weights_pd['digit'] = pd.Series(targets).map(lambda x: 'Digit {}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_embedding(interval=19):\n",
    "\n",
    "#     for i in range(interval):\n",
    "\n",
    "#         embedding = reducer.fit_transform(np.delete(weights_array,np.s_[500+i:-1],1))\n",
    "\n",
    "#         plot_fig(embedding,targets,500+i)\n",
    "\n",
    "#     embedding = reducer.fit_transform(np.delete(weights_array,np.s_[9049+i:-1],1))\n",
    "#     plot_fig(embedding,targets,9049)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/labels\", 'rb') as fp:\n",
    "#     targets = pickle.load(fp)\n",
    "\n",
    "# with open('../data/weights_dictionary.pkl', 'rb') as fp:\n",
    "#     weights = pickle.load(fp)\n",
    "\n",
    "# targets = np.array(targets) ##new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
